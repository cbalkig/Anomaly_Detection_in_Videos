{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Copy of train.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cbalkig/Anomaly_Detection_in_Videos/blob/master/train_v3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5l0wNtKs7vP"
      },
      "source": [
        "import os\n",
        "from os import listdir\n",
        "from os.path import join, isdir\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import keras\n",
        "from keras.layers import Conv2DTranspose, ConvLSTM2D, TimeDistributed, Conv2D, Flatten, Dense, Dropout, Activation, MaxPooling2D, Activation\n",
        "from keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Conv2D, Conv3D, BatchNormalization\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from numpy import save, load\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDd3-dzSs82m"
      },
      "source": [
        "working_directory = '/content/drive/MyDrive/AnomalyDetectionInVideos'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKtCPjOYs97U"
      },
      "source": [
        "class Config:\n",
        "    DATASET_PATH = os.path.join(working_directory, \"files\")\n",
        "    BATCH_SIZE = 16\n",
        "    EPOCHS = 10\n",
        "    MODEL_PATH = os.path.join(working_directory, \"model.hdf5\")\n",
        "    SAMPLES_COUNT = 0\n",
        "    FILTERS_COUNT = 4\n",
        "    IMAGE_SIZE = 256"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OupvfKWU7xLe"
      },
      "source": [
        "def get_samples_data():\n",
        "    sample_count = 0\n",
        "    # Calculate the min number of frames in a video\n",
        "    for f in sorted(listdir(Config.DATASET_PATH)):\n",
        "        directory_path = join(Config.DATASET_PATH, f)\n",
        "        if isdir(directory_path):\n",
        "            sample_count = sample_count + len(listdir(directory_path))\n",
        "            for c in listdir(directory_path):\n",
        "              if len(c) < 7:\n",
        "                os.rename(join(directory_path, c), join(directory_path, c.zfill(7)))\n",
        "    print(\"Number of samples\", sample_count)\n",
        "    Config.SAMPLES_COUNT = sample_count"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NlhxTlv71Vm"
      },
      "source": [
        "get_samples_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEitB-7qtDeZ"
      },
      "source": [
        "def get_training_set():\n",
        "    # Process all videos and generate videos np array with shape: (Config.SAMPLES_COUNT, Config.IMAGE_SIZE, Config.IMAGE_SIZE)\n",
        "    data = []\n",
        "    labels = []\n",
        "    sample_count = 0\n",
        "    max_count = 0\n",
        "    for f in sorted(listdir(Config.DATASET_PATH)):\n",
        "        directory_path = join(Config.DATASET_PATH, f)\n",
        "        if isdir(directory_path):\n",
        "            print(\"Processing\", directory_path)\n",
        "            count = 0\n",
        "            for c in sorted(listdir(directory_path)):\n",
        "                #print(\"Frame #\", count)\n",
        "                img_path = join(directory_path, c)\n",
        "                if str(img_path)[-3:] == \"tif\":\n",
        "                    img = Image.open(img_path).resize((Config.IMAGE_SIZE, Config.IMAGE_SIZE))\n",
        "                    img = np.array(img, dtype=np.float32) / 256.0\n",
        "                    img = np.reshape(img, img.shape + (1,))\n",
        "                    data.append(img)\n",
        "                    labels.append(count)\n",
        "                    sample_count = sample_count + 1\n",
        "                    if count > max_count:\n",
        "                        max_count = count\n",
        "                    count = count + 1\n",
        "    return data, labels, max_count"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S93thOCmzGJd"
      },
      "source": [
        "train_data, train_labels, max_count = get_training_set()\n",
        "print(\"Number of classes\", max_count)\n",
        "train_data = np.array(train_data)\n",
        "train_labels = np.array(train_labels)\n",
        "save(join(Config.DATASET_PATH, 'train_data_' + str(Config.IMAGE_SIZE) + '.npy'), train_data)\n",
        "print(\"Shape of training set\", train_data.shape)\n",
        "save(join(Config.DATASET_PATH, 'train_labels_' + str(Config.IMAGE_SIZE) + '.npy'), train_labels)\n",
        "print(\"Shape of training set\", train_labels.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfXR-gBgJbMw"
      },
      "source": [
        "training_set = load(join(Config.DATASET_PATH, 'train_data_' + str(Config.IMAGE_SIZE) + '.npy'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LBLhgZkq6Z2"
      },
      "source": [
        "def make_model(input_shape, num_classes):\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, kernel_size=3, activation=\"relu\", input_shape=input_shape))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Conv2D(32, kernel_size=3, activation=\"relu\", input_shape=input_shape))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Conv2D(64, kernel_size=3, activation=\"relu\", input_shape=input_shape))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(64, activation=\"relu\"))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(num_classes, activation=\"softmax\"))\n",
        "    model.summary()\n",
        "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxThkfDO3jDe"
      },
      "source": [
        "def train_model(reload_model=True):\n",
        "    if reload_model:\n",
        "        return load_model(Config.MODEL_PATH)\n",
        "    model = make_model((Config.IMAGE_SIZE, Config.IMAGE_SIZE, 1), max_count + 1)\n",
        "    history = model.fit(train_data, one_hot_train_labels, epochs=Config.EPOCHS, batch_size=Config.BATCH_SIZE)\n",
        "    print(history)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5YHiwtlwRrZ"
      },
      "source": [
        "one_hot_train_labels = np.zeros((len(train_labels), max_count + 1))\n",
        "for idx in range(len(train_labels)):\n",
        "    one_hot_train_labels[idx][train_labels[idx]] = 1      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fe_09tfotJjQ"
      },
      "source": [
        "model = train_model(reload_model=False)\n",
        "print(\"Model is ready.\")\n",
        "model.save(Config.MODEL_PATH)\n",
        "print(\"Model saved : \", Config.MODEL_PATH)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}