{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Copy of train.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cbalkig/Anomaly_Detection_in_Videos/blob/master/train_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5l0wNtKs7vP"
      },
      "source": [
        "import os\n",
        "from os import listdir\n",
        "from os.path import join, isdir\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import keras\n",
        "from keras.layers import Conv2DTranspose, ConvLSTM2D, TimeDistributed, Conv2D\n",
        "from keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Conv2D, Conv3D, BatchNormalization\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from numpy import save, load"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDd3-dzSs82m"
      },
      "source": [
        "working_directory = '/content/drive/MyDrive/AnomalyDetectionInVideos'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKtCPjOYs97U"
      },
      "source": [
        "class Config:\n",
        "    DATASET_PATH = os.path.join(working_directory, \"files\")\n",
        "    BATCH_SIZE = 4\n",
        "    EPOCHS = 5\n",
        "    MODEL_PATH = os.path.join(working_directory, \"model.hdf5\")\n",
        "    FRAME_SIZE = 159\n",
        "    SAMPLES_COUNT = 36\n",
        "    FILTERS_COUNT = 5\n",
        "    IMAGE_SIZE = 128"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OupvfKWU7xLe"
      },
      "source": [
        "def get_samples_data():\n",
        "    threshold = 1000\n",
        "    sample_count = 0\n",
        "    # Calculate the min number of frames in a video\n",
        "    for f in sorted(listdir(Config.DATASET_PATH)):\n",
        "        directory_path = join(Config.DATASET_PATH, f)\n",
        "        if isdir(directory_path):\n",
        "            sample_count = sample_count + 1\n",
        "            count = len(listdir(directory_path))\n",
        "            print(f, count)\n",
        "            if count < threshold:\n",
        "              threshold = count\n",
        "            for c in listdir(directory_path):\n",
        "              if len(c) < 7:\n",
        "                os.rename(join(directory_path, c), join(directory_path, c.zfill(7)))\n",
        "    print(\"Min folder threshold will be\", threshold)\n",
        "    print(\"Number of samples\", sample_count)\n",
        "    Config.FRAME_SIZE = threshold\n",
        "    Config.SAMPLES_COUNT = sample_count"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NlhxTlv71Vm"
      },
      "source": [
        "#get_samples_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEitB-7qtDeZ"
      },
      "source": [
        "def get_training_set():\n",
        "    # Process all videos and generate videos np array with shape: (Config.SAMPLES_COUNT, Config.FRAME_SIZE, Config.IMAGE_SIZE, Config.IMAGE_SIZE)\n",
        "    videos = np.zeros((Config.SAMPLES_COUNT, Config.FRAME_SIZE, Config.IMAGE_SIZE, Config.IMAGE_SIZE, 1))\n",
        "    sample_count = 0\n",
        "    for f in sorted(listdir(Config.DATASET_PATH)):\n",
        "        directory_path = join(Config.DATASET_PATH, f)\n",
        "        if isdir(directory_path):\n",
        "            print(\"Processing\", directory_path)\n",
        "            count = 0\n",
        "            for c in sorted(listdir(directory_path)):\n",
        "                #print(\"Frame #\", count)\n",
        "                img_path = join(directory_path, c)\n",
        "                if str(img_path)[-3:] == \"tif\":\n",
        "                    img = Image.open(img_path).resize((Config.IMAGE_SIZE, Config.IMAGE_SIZE))\n",
        "                    img = np.array(img, dtype=np.float32) / 256.0\n",
        "                    img = np.reshape(img, img.shape + (1,))\n",
        "                    videos[sample_count][count] = img\n",
        "                count = count + 1\n",
        "                if count == Config.FRAME_SIZE:\n",
        "                    break\n",
        "            sample_count = sample_count + 1\n",
        "    return videos"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S93thOCmzGJd"
      },
      "source": [
        "#training_set = get_training_set()\n",
        "#training_set = np.array(training_set)\n",
        "#save(join(Config.DATASET_PATH, 'train_data_' + str(Config.IMAGE_SIZE) + '.npy'), training_set)\n",
        "#print(\"Shape of training set\", training_set.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfXR-gBgJbMw"
      },
      "source": [
        "training_set = load(join(Config.DATASET_PATH, 'train_data_' + str(Config.IMAGE_SIZE) + '.npy'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxThkfDO3jDe"
      },
      "source": [
        "def train_model(reload_model=True):\n",
        "    if not reload_model:\n",
        "        return load_model(Config.MODEL_PATH,custom_objects={'BatchNormalization': BatchNormalization})\n",
        "    model = Sequential()\n",
        "    model.add(ConvLSTM2D(filters=Config.FILTERS_COUNT, kernel_size=(3, 3), input_shape=(Config.FRAME_SIZE, Config.IMAGE_SIZE, Config.IMAGE_SIZE, 1), padding=\"same\", return_sequences=True))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(ConvLSTM2D(filters=Config.FILTERS_COUNT, kernel_size=(3, 3), padding=\"same\", return_sequences=True))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(ConvLSTM2D(filters=Config.FILTERS_COUNT, kernel_size=(3, 3), padding=\"same\", return_sequences=True))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv3D(filters=1, kernel_size=(3, 3, 3), activation=\"sigmoid\", padding=\"same\", data_format=\"channels_last\"))\n",
        "    model.compile(loss=\"binary_crossentropy\", optimizer=\"adadelta\", metrics=[\"accuracy\"])\n",
        "    model.summary()\n",
        "    model.fit(training_set, training_set,\n",
        "            batch_size=Config.BATCH_SIZE, epochs=Config.EPOCHS, shuffle=False, verbose=1, \n",
        "            callbacks=[keras.callbacks.TensorBoard(log_dir=\"logs/final\", histogram_freq=1, write_graph=True, write_images=True)])\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fe_09tfotJjQ"
      },
      "source": [
        "model = train_model()\n",
        "print(\"Model is ready.\")\n",
        "model.save(Config.MODEL_PATH)\n",
        "print(\"Model saved : \", Config.MODEL_PATH)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}