{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of train.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cbalkig/Anomaly_Detection_in_Videos/blob/master/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aeXyd7D56eyv",
        "outputId": "4ceeee99-5d4b-4fc1-fc1a-b9bceb995f35"
      },
      "source": [
        "pip install keras_layer_normalization"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras_layer_normalization in /usr/local/lib/python3.6/dist-packages (0.14.0)\n",
            "Requirement already satisfied: Keras in /usr/local/lib/python3.6/dist-packages (from keras_layer_normalization) (2.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras_layer_normalization) (1.19.4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras->keras_layer_normalization) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_layer_normalization) (1.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras->keras_layer_normalization) (2.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->Keras->keras_layer_normalization) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxThkfDO3jDe",
        "outputId": "ad51b5d0-ae22-4d68-9931-93a21c276139"
      },
      "source": [
        "import os\n",
        "from os import listdir\n",
        "from os.path import join, isdir\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import keras\n",
        "from keras.layers import Conv2DTranspose, ConvLSTM2D, TimeDistributed, Conv2D\n",
        "from keras.models import Sequential, load_model\n",
        "from keras_layer_normalization import LayerNormalization\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "working_directory = '/content/drive/MyDrive/AnomalyDetectionInVideos'\n",
        "\n",
        "\n",
        "class Config:\n",
        "    DATASET_PATH = os.path.join(working_directory, \"files\")\n",
        "    BATCH_SIZE = 4\n",
        "    EPOCHS = 5\n",
        "    WIDTH = 256\n",
        "    HEIGHT = 256\n",
        "    FRAME_SIZE = 10\n",
        "    MODEL_PATH = os.path.join(working_directory, \"model.hdf5\")\n",
        "\n",
        "\n",
        "def get_clips_by_stride(stride, frames_list, sequence_size):\n",
        "    \"\"\" For data augmenting purposes.\n",
        "    Parameters\n",
        "    ----------\n",
        "    stride : int\n",
        "        The distance between two consecutive frames\n",
        "    frames_list : list\n",
        "        A list of sorted frames of shape 256 X 256\n",
        "    sequence_size: int\n",
        "        The size of the lstm sequence\n",
        "    Returns\n",
        "    -------\n",
        "    list\n",
        "        A list of clips , FRAME_SIZE frames each\n",
        "    \"\"\"\n",
        "    clips = []\n",
        "    sz = len(frames_list)\n",
        "    clip = np.zeros(shape=(sequence_size, 256, 256, 1))\n",
        "    cnt = 0\n",
        "    for start in range(0, stride):\n",
        "        for i in range(start, sz, stride):\n",
        "            clip[cnt, :, :, 0] = frames_list[i]\n",
        "            cnt = cnt + 1\n",
        "            if cnt == sequence_size:\n",
        "                clips.append(clip)\n",
        "                cnt = 0\n",
        "    return clips\n",
        "\n",
        "def get_training_set():\n",
        "    \"\"\"\n",
        "    Returns\n",
        "    -------\n",
        "    list\n",
        "        A list of training sequences of shape (NUMBER_OF_SEQUENCES,SINGLE_SEQUENCE_SIZE,FRAME_WIDTH,FRAME_HEIGHT,1)\n",
        "    \"\"\"\n",
        "    clips = []\n",
        "    threshold = 1000\n",
        "    for f in sorted(listdir(Config.DATASET_PATH)):\n",
        "        directory_path = join(Config.DATASET_PATH, f)\n",
        "        if isdir(directory_path):\n",
        "            count = len(listdir(directory_path))\n",
        "            print(directory_path, count)\n",
        "            if count < threshold:\n",
        "              threshold = count\n",
        "            for c in listdir(directory_path):\n",
        "              if len(c) < 7:\n",
        "                os.rename(join(directory_path, c), join(directory_path, c.zfill(7)))\n",
        "\n",
        "    print(\"Min folder threshold will be\", threshold)\n",
        "    # loop over the training folders (Train000,Train001,..)\n",
        "    for f in sorted(listdir(Config.DATASET_PATH)):\n",
        "        directory_path = join(Config.DATASET_PATH, f)\n",
        "        if isdir(directory_path):\n",
        "            print(\"Processing\", directory_path)\n",
        "            all_frames = []\n",
        "            count = 0\n",
        "            # loop over all the images in the folder (0.tif,1.tif,..,199.tif)\n",
        "            for c in sorted(listdir(directory_path)):\n",
        "                count = count + 1\n",
        "                if count > threshold:\n",
        "                    break\n",
        "                img_path = join(directory_path, c)\n",
        "                if str(img_path)[-3:] == \"tif\":\n",
        "                    img = Image.open(img_path).resize((256, 256))\n",
        "                    img = np.array(img, dtype=np.float32) / 256.0\n",
        "                    all_frames.append(img)\n",
        "            # get the FRAME_SIZE-frames sequences from the list of images after applying data augmentation\n",
        "            for stride in range(1, 3):\n",
        "                clips.extend(get_clips_by_stride(stride=stride, frames_list=all_frames, sequence_size=Config.FRAME_SIZE))\n",
        "    return clips\n",
        "\n",
        "\n",
        "def get_model(reload_model=True):\n",
        "    \"\"\"\n",
        "    Parameters\n",
        "    ----------\n",
        "    reload_model : bool\n",
        "        Load saved model or retrain it\n",
        "    \"\"\"\n",
        "    if not reload_model:\n",
        "        return load_model(Config.MODEL_PATH,custom_objects={'LayerNormalization': LayerNormalization})\n",
        "    training_set = get_training_set()\n",
        "    training_set = np.array(training_set)\n",
        "    seq = Sequential()\n",
        "    seq.add(TimeDistributed(Conv2D(128, (11, 11), strides=4, padding=\"same\"), batch_input_shape=(None, Config.FRAME_SIZE, 256, 256, 1)))\n",
        "    seq.add(LayerNormalization())\n",
        "    seq.add(TimeDistributed(Conv2D(64, (5, 5), strides=2, padding=\"same\")))\n",
        "    seq.add(LayerNormalization())\n",
        "    # # # # #\n",
        "    seq.add(ConvLSTM2D(64, (3, 3), padding=\"same\", return_sequences=True))\n",
        "    seq.add(LayerNormalization())\n",
        "    seq.add(ConvLSTM2D(32, (3, 3), padding=\"same\", return_sequences=True))\n",
        "    seq.add(LayerNormalization())\n",
        "    seq.add(ConvLSTM2D(64, (3, 3), padding=\"same\", return_sequences=True))\n",
        "    seq.add(LayerNormalization())\n",
        "    # # # # #\n",
        "    seq.add(TimeDistributed(Conv2DTranspose(64, (5, 5), strides=2, padding=\"same\")))\n",
        "    seq.add(LayerNormalization())\n",
        "    seq.add(TimeDistributed(Conv2DTranspose(128, (11, 11), strides=4, padding=\"same\")))\n",
        "    seq.add(LayerNormalization())\n",
        "    seq.add(TimeDistributed(Conv2D(1, (11, 11), activation=\"sigmoid\", padding=\"same\")))\n",
        "    print(seq.summary())\n",
        "    seq.compile(loss='mse', optimizer=keras.optimizers.Adam(lr=1e-4, decay=1e-5, epsilon=1e-6))\n",
        "    seq.fit(training_set, training_set,\n",
        "            batch_size=Config.BATCH_SIZE, epochs=Config.EPOCHS, shuffle=False)\n",
        "    seq.save(Config.MODEL_PATH)\n",
        "    return seq\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    model = get_model()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/AnomalyDetectionInVideos/files/001dbbb8-b749-4ce0-a90d-740b8a783f35 215\n",
            "/content/drive/MyDrive/AnomalyDetectionInVideos/files/0b1aab89-cbce-47af-a426-693f45c19acc 195\n",
            "/content/drive/MyDrive/AnomalyDetectionInVideos/files/2195f4e0-76c9-465f-9123-8261ae863112 214\n",
            "/content/drive/MyDrive/AnomalyDetectionInVideos/files/25f477c3-6deb-4ae0-b0ca-1cf107e03dd9 196\n",
            "/content/drive/MyDrive/AnomalyDetectionInVideos/files/2e900a0f-dc64-4b45-a4cf-5a4a1f92547b 238\n",
            "/content/drive/MyDrive/AnomalyDetectionInVideos/files/4bb580ce-85a2-493d-9956-4d2e86cd4141 231\n",
            "/content/drive/MyDrive/AnomalyDetectionInVideos/files/6dd659ff-12aa-437a-a5b2-3364a879a5fc 211\n",
            "/content/drive/MyDrive/AnomalyDetectionInVideos/files/71ec8eb2-5e89-45e0-b019-a3be044c6355 202\n",
            "/content/drive/MyDrive/AnomalyDetectionInVideos/files/74007bb7-b182-4bf4-9b11-e1bb6606e2ab 159\n",
            "/content/drive/MyDrive/AnomalyDetectionInVideos/files/769a3c79-f730-4f05-becf-ee9535131173 223\n",
            "/content/drive/MyDrive/AnomalyDetectionInVideos/files/7927fbca-aca1-4df1-8d3b-788d26c106e1 225\n",
            "/content/drive/MyDrive/AnomalyDetectionInVideos/files/7be50887-eb8f-473b-b85f-566df6cea1b4 248\n",
            "/content/drive/MyDrive/AnomalyDetectionInVideos/files/9185cf7a-c28d-40dd-8768-5bb28cbeb2c6 223\n",
            "/content/drive/MyDrive/AnomalyDetectionInVideos/files/938fd6aa-ad18-40e6-90e0-2ee7a397e8cf 201\n",
            "/content/drive/MyDrive/AnomalyDetectionInVideos/files/9c67eb54-6db3-4a66-804b-59f5e853f6eb 217\n",
            "/content/drive/MyDrive/AnomalyDetectionInVideos/files/a2051be4-c866-49e9-9b38-a58562109957 219\n",
            "/content/drive/MyDrive/AnomalyDetectionInVideos/files/b84bd1f4-7026-495a-9247-4aa3b5dd1b45 217\n",
            "/content/drive/MyDrive/AnomalyDetectionInVideos/files/c4e84b52-593d-40a9-b3e0-549108d58f3e 213\n",
            "/content/drive/MyDrive/AnomalyDetectionInVideos/files/cad1897f-4c81-40ff-96a2-2b722c5f259a 215\n",
            "/content/drive/MyDrive/AnomalyDetectionInVideos/files/e7a1a4ba-8f09-4b63-98ab-d299110c0c72 236\n",
            "/content/drive/MyDrive/AnomalyDetectionInVideos/files/f5d70039-7387-4f7b-ac97-38534f444f8e 218\n",
            "/content/drive/MyDrive/AnomalyDetectionInVideos/files/f6832f56-c6e3-4e37-9e77-73df4ff87e94 163\n",
            "Min folder threshold will be 159\n",
            "Processing /content/drive/MyDrive/AnomalyDetectionInVideos/files/001dbbb8-b749-4ce0-a90d-740b8a783f35\n",
            "Processing /content/drive/MyDrive/AnomalyDetectionInVideos/files/0b1aab89-cbce-47af-a426-693f45c19acc\n",
            "Processing /content/drive/MyDrive/AnomalyDetectionInVideos/files/2195f4e0-76c9-465f-9123-8261ae863112\n",
            "Processing /content/drive/MyDrive/AnomalyDetectionInVideos/files/25f477c3-6deb-4ae0-b0ca-1cf107e03dd9\n",
            "Processing /content/drive/MyDrive/AnomalyDetectionInVideos/files/2e900a0f-dc64-4b45-a4cf-5a4a1f92547b\n",
            "Processing /content/drive/MyDrive/AnomalyDetectionInVideos/files/4bb580ce-85a2-493d-9956-4d2e86cd4141\n",
            "Processing /content/drive/MyDrive/AnomalyDetectionInVideos/files/6dd659ff-12aa-437a-a5b2-3364a879a5fc\n",
            "Processing /content/drive/MyDrive/AnomalyDetectionInVideos/files/71ec8eb2-5e89-45e0-b019-a3be044c6355\n",
            "Processing /content/drive/MyDrive/AnomalyDetectionInVideos/files/74007bb7-b182-4bf4-9b11-e1bb6606e2ab\n",
            "Processing /content/drive/MyDrive/AnomalyDetectionInVideos/files/769a3c79-f730-4f05-becf-ee9535131173\n",
            "Processing /content/drive/MyDrive/AnomalyDetectionInVideos/files/7927fbca-aca1-4df1-8d3b-788d26c106e1\n",
            "Processing /content/drive/MyDrive/AnomalyDetectionInVideos/files/7be50887-eb8f-473b-b85f-566df6cea1b4\n",
            "Processing /content/drive/MyDrive/AnomalyDetectionInVideos/files/9185cf7a-c28d-40dd-8768-5bb28cbeb2c6\n",
            "Processing /content/drive/MyDrive/AnomalyDetectionInVideos/files/938fd6aa-ad18-40e6-90e0-2ee7a397e8cf\n",
            "Processing /content/drive/MyDrive/AnomalyDetectionInVideos/files/9c67eb54-6db3-4a66-804b-59f5e853f6eb\n",
            "Processing /content/drive/MyDrive/AnomalyDetectionInVideos/files/a2051be4-c866-49e9-9b38-a58562109957\n",
            "Processing /content/drive/MyDrive/AnomalyDetectionInVideos/files/b84bd1f4-7026-495a-9247-4aa3b5dd1b45\n",
            "Processing /content/drive/MyDrive/AnomalyDetectionInVideos/files/c4e84b52-593d-40a9-b3e0-549108d58f3e\n",
            "Processing /content/drive/MyDrive/AnomalyDetectionInVideos/files/cad1897f-4c81-40ff-96a2-2b722c5f259a\n",
            "Processing /content/drive/MyDrive/AnomalyDetectionInVideos/files/e7a1a4ba-8f09-4b63-98ab-d299110c0c72\n",
            "Processing /content/drive/MyDrive/AnomalyDetectionInVideos/files/f5d70039-7387-4f7b-ac97-38534f444f8e\n",
            "Processing /content/drive/MyDrive/AnomalyDetectionInVideos/files/f6832f56-c6e3-4e37-9e77-73df4ff87e94\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "time_distributed_5 (TimeDist (None, 10, 64, 64, 128)   15616     \n",
            "_________________________________________________________________\n",
            "layer_normalization_7 (Layer (None, 10, 64, 64, 128)   256       \n",
            "_________________________________________________________________\n",
            "time_distributed_6 (TimeDist (None, 10, 32, 32, 64)    204864    \n",
            "_________________________________________________________________\n",
            "layer_normalization_8 (Layer (None, 10, 32, 32, 64)    128       \n",
            "_________________________________________________________________\n",
            "conv_lst_m2d_3 (ConvLSTM2D)  (None, 10, 32, 32, 64)    295168    \n",
            "_________________________________________________________________\n",
            "layer_normalization_9 (Layer (None, 10, 32, 32, 64)    128       \n",
            "_________________________________________________________________\n",
            "conv_lst_m2d_4 (ConvLSTM2D)  (None, 10, 32, 32, 32)    110720    \n",
            "_________________________________________________________________\n",
            "layer_normalization_10 (Laye (None, 10, 32, 32, 32)    64        \n",
            "_________________________________________________________________\n",
            "conv_lst_m2d_5 (ConvLSTM2D)  (None, 10, 32, 32, 64)    221440    \n",
            "_________________________________________________________________\n",
            "layer_normalization_11 (Laye (None, 10, 32, 32, 64)    128       \n",
            "_________________________________________________________________\n",
            "time_distributed_7 (TimeDist (None, 10, 64, 64, 64)    102464    \n",
            "_________________________________________________________________\n",
            "layer_normalization_12 (Laye (None, 10, 64, 64, 64)    128       \n",
            "_________________________________________________________________\n",
            "time_distributed_8 (TimeDist (None, 10, 256, 256, 128) 991360    \n",
            "_________________________________________________________________\n",
            "layer_normalization_13 (Laye (None, 10, 256, 256, 128) 256       \n",
            "_________________________________________________________________\n",
            "time_distributed_9 (TimeDist (None, 10, 256, 256, 1)   15489     \n",
            "=================================================================\n",
            "Total params: 1,958,209\n",
            "Trainable params: 1,958,209\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/5\n",
            "165/165 [==============================] - 111s 591ms/step - loss: 0.0465\n",
            "Epoch 2/5\n",
            "165/165 [==============================] - 97s 591ms/step - loss: 0.0084\n",
            "Epoch 3/5\n",
            "165/165 [==============================] - 97s 590ms/step - loss: 0.0050\n",
            "Epoch 4/5\n",
            "165/165 [==============================] - 97s 589ms/step - loss: 0.0041\n",
            "Epoch 5/5\n",
            "165/165 [==============================] - 97s 590ms/step - loss: 0.0031\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}