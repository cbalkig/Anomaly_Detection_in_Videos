{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of train.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cbalkig/Anomaly_Detection_in_Videos/blob/master/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aeXyd7D56eyv",
        "outputId": "bbaf787f-f71f-4707-ae92-eff5d94b324e"
      },
      "source": [
        "pip install keras_layer_normalization"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras_layer_normalization in /usr/local/lib/python3.6/dist-packages (0.14.0)\n",
            "Requirement already satisfied: Keras in /usr/local/lib/python3.6/dist-packages (from keras_layer_normalization) (2.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras_layer_normalization) (1.19.4)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras->keras_layer_normalization) (2.10.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_layer_normalization) (1.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras->keras_layer_normalization) (3.13)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->Keras->keras_layer_normalization) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxThkfDO3jDe",
        "outputId": "ba850a37-5a8f-4381-f947-0b47d7ef37da"
      },
      "source": [
        "import os\n",
        "from os import listdir\n",
        "from os.path import join, isdir\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import keras\n",
        "from keras.layers import Conv2DTranspose, ConvLSTM2D, TimeDistributed, Conv2D\n",
        "from keras.models import Sequential, load_model\n",
        "from keras_layer_normalization import LayerNormalization\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "working_directory = '/content/drive/MyDrive/AnomalyDetectionInVideos'\n",
        "\n",
        "\n",
        "class Config:\n",
        "    DATASET_PATH = os.path.join(working_directory, \"files\")\n",
        "    BATCH_SIZE = 4\n",
        "    EPOCHS = 5\n",
        "    WIDTH = 256\n",
        "    HEIGHT = 256\n",
        "    FRAME_SIZE = 10\n",
        "    MODEL_PATH = os.path.join(working_directory, \"model.hdf5\")\n",
        "\n",
        "\n",
        "def get_clips_by_stride(stride, frames_list, sequence_size):\n",
        "    \"\"\" For data augmenting purposes.\n",
        "    Parameters\n",
        "    ----------\n",
        "    stride : int\n",
        "        The distance between two consecutive frames\n",
        "    frames_list : list\n",
        "        A list of sorted frames of shape 256 X 256\n",
        "    sequence_size: int\n",
        "        The size of the lstm sequence\n",
        "    Returns\n",
        "    -------\n",
        "    list\n",
        "        A list of clips , FRAME_SIZE frames each\n",
        "    \"\"\"\n",
        "    clips = []\n",
        "    sz = len(frames_list)\n",
        "    clip = np.zeros(shape=(sequence_size, 256, 256, 1))\n",
        "    cnt = 0\n",
        "    for start in range(0, stride):\n",
        "        for i in range(start, sz, stride):\n",
        "            clip[cnt, :, :, 0] = frames_list[i]\n",
        "            cnt = cnt + 1\n",
        "            if cnt == sequence_size:\n",
        "                clips.append(clip)\n",
        "                cnt = 0\n",
        "    return clips\n",
        "\n",
        "def get_training_set():\n",
        "    \"\"\"\n",
        "    Returns\n",
        "    -------\n",
        "    list\n",
        "        A list of training sequences of shape (NUMBER_OF_SEQUENCES,SINGLE_SEQUENCE_SIZE,FRAME_WIDTH,FRAME_HEIGHT,1)\n",
        "    \"\"\"\n",
        "    clips = []\n",
        "    threshold = 1000\n",
        "    for f in sorted(listdir(Config.DATASET_PATH)):\n",
        "        directory_path = join(Config.DATASET_PATH, f)\n",
        "        if isdir(directory_path):\n",
        "            count = len(listdir(directory_path))\n",
        "            print(directory_path, count)\n",
        "            if count < threshold:\n",
        "              threshold = count\n",
        "            for c in listdir(directory_path):\n",
        "              if len(c) < 7:\n",
        "                os.rename(join(directory_path, c), join(directory_path, c.zfill(7)))\n",
        "\n",
        "    print(\"Min folder threshold will be\", threshold)\n",
        "    # loop over the training folders (Train000,Train001,..)\n",
        "    for f in sorted(listdir(Config.DATASET_PATH)):\n",
        "        directory_path = join(Config.DATASET_PATH, f)\n",
        "        if isdir(directory_path):\n",
        "            print(\"Processing\", directory_path)\n",
        "            all_frames = []\n",
        "            count = 0\n",
        "            # loop over all the images in the folder (0.tif,1.tif,..,199.tif)\n",
        "            for c in sorted(listdir(directory_path)):\n",
        "                count = count + 1\n",
        "                if count > threshold:\n",
        "                    break\n",
        "                img_path = join(directory_path, c)\n",
        "                if str(img_path)[-3:] == \"tif\":\n",
        "                    img = Image.open(img_path).resize((256, 256))\n",
        "                    img = np.array(img, dtype=np.float32) / 256.0\n",
        "                    all_frames.append(img)\n",
        "            # get the FRAME_SIZE-frames sequences from the list of images after applying data augmentation\n",
        "            for stride in range(1, 3):\n",
        "                clips.extend(get_clips_by_stride(stride=stride, frames_list=all_frames, sequence_size=Config.FRAME_SIZE))\n",
        "    return clips\n",
        "\n",
        "\n",
        "def get_model(reload_model=True):\n",
        "    \"\"\"\n",
        "    Parameters\n",
        "    ----------\n",
        "    reload_model : bool\n",
        "        Load saved model or retrain it\n",
        "    \"\"\"\n",
        "    if not reload_model:\n",
        "        return load_model(Config.MODEL_PATH,custom_objects={'LayerNormalization': LayerNormalization})\n",
        "    training_set = get_training_set()\n",
        "    training_set = np.array(training_set)\n",
        "    seq = Sequential()\n",
        "    seq.add(TimeDistributed(Conv2D(128, (11, 11), strides=4, padding=\"same\"), batch_input_shape=(None, Config.FRAME_SIZE, 256, 256, 1)))\n",
        "    seq.add(LayerNormalization())\n",
        "    seq.add(TimeDistributed(Conv2D(64, (5, 5), strides=2, padding=\"same\")))\n",
        "    seq.add(LayerNormalization())\n",
        "    # # # # #\n",
        "    seq.add(ConvLSTM2D(64, (3, 3), padding=\"same\", return_sequences=True))\n",
        "    seq.add(LayerNormalization())\n",
        "    seq.add(ConvLSTM2D(32, (3, 3), padding=\"same\", return_sequences=True))\n",
        "    seq.add(LayerNormalization())\n",
        "    seq.add(ConvLSTM2D(64, (3, 3), padding=\"same\", return_sequences=True))\n",
        "    seq.add(LayerNormalization())\n",
        "    # # # # #\n",
        "    seq.add(TimeDistributed(Conv2DTranspose(64, (5, 5), strides=2, padding=\"same\")))\n",
        "    seq.add(LayerNormalization())\n",
        "    seq.add(TimeDistributed(Conv2DTranspose(128, (11, 11), strides=4, padding=\"same\")))\n",
        "    seq.add(LayerNormalization())\n",
        "    seq.add(TimeDistributed(Conv2D(1, (11, 11), activation=\"sigmoid\", padding=\"same\")))\n",
        "    print(seq.summary())\n",
        "    seq.compile(loss='mse', optimizer=keras.optimizers.Adam(lr=1e-4, decay=1e-5, epsilon=1e-6))\n",
        "    seq.fit(training_set, training_set,\n",
        "            batch_size=Config.BATCH_SIZE, epochs=Config.EPOCHS, shuffle=False)\n",
        "    seq.save(Config.MODEL_PATH)\n",
        "    return seq\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    model = get_model()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/AnomalyDetectionInVideos/files/001dbbb8-b749-4ce0-a90d-740b8a783f35 215\n",
            "/content/drive/MyDrive/AnomalyDetectionInVideos/files/083e9a31-84d9-455d-91e7-d1b0921b4921 219\n",
            "/content/drive/MyDrive/AnomalyDetectionInVideos/files/0b1aab89-cbce-47af-a426-693f45c19acc 195\n",
            "/content/drive/MyDrive/AnomalyDetectionInVideos/files/1474d8ce-335a-4568-b786-aa01d763e941 218\n",
            "/content/drive/MyDrive/AnomalyDetectionInVideos/files/1f51d251-79aa-4bb3-b9f3-01a8275dab63 211\n",
            "/content/drive/MyDrive/AnomalyDetectionInVideos/files/2195f4e0-76c9-465f-9123-8261ae863112 214\n",
            "/content/drive/MyDrive/AnomalyDetectionInVideos/files/25f477c3-6deb-4ae0-b0ca-1cf107e03dd9 196\n",
            "/content/drive/MyDrive/AnomalyDetectionInVideos/files/2e900a0f-dc64-4b45-a4cf-5a4a1f92547b 238\n",
            "/content/drive/MyDrive/AnomalyDetectionInVideos/files/320b7780-a1af-480f-a7cb-b8c5d29c1d4e 191\n",
            "/content/drive/MyDrive/AnomalyDetectionInVideos/files/4bb580ce-85a2-493d-9956-4d2e86cd4141 231\n",
            "/content/drive/MyDrive/AnomalyDetectionInVideos/files/6dd659ff-12aa-437a-a5b2-3364a879a5fc 211\n",
            "/content/drive/MyDrive/AnomalyDetectionInVideos/files/71ec8eb2-5e89-45e0-b019-a3be044c6355 202\n",
            "/content/drive/MyDrive/AnomalyDetectionInVideos/files/74007bb7-b182-4bf4-9b11-e1bb6606e2ab 159\n",
            "/content/drive/MyDrive/AnomalyDetectionInVideos/files/769a3c79-f730-4f05-becf-ee9535131173 223\n",
            "/content/drive/MyDrive/AnomalyDetectionInVideos/files/7927fbca-aca1-4df1-8d3b-788d26c106e1 225\n",
            "/content/drive/MyDrive/AnomalyDetectionInVideos/files/7be50887-eb8f-473b-b85f-566df6cea1b4 248\n",
            "/content/drive/MyDrive/AnomalyDetectionInVideos/files/809c6bfb-585f-4158-9dc9-a8ad3e6717a2 210\n",
            "/content/drive/MyDrive/AnomalyDetectionInVideos/files/897a7710-2a2c-4af6-833d-efd2fc5492fe 215\n",
            "/content/drive/MyDrive/AnomalyDetectionInVideos/files/9185cf7a-c28d-40dd-8768-5bb28cbeb2c6 223\n",
            "/content/drive/MyDrive/AnomalyDetectionInVideos/files/935bb3da-3591-42fc-a41a-b514db2b5a3d 227\n",
            "/content/drive/MyDrive/AnomalyDetectionInVideos/files/938fd6aa-ad18-40e6-90e0-2ee7a397e8cf 201\n",
            "/content/drive/MyDrive/AnomalyDetectionInVideos/files/9417e18b-f432-4907-b9c7-2a28cd43b1e7 212\n",
            "/content/drive/MyDrive/AnomalyDetectionInVideos/files/9c67eb54-6db3-4a66-804b-59f5e853f6eb 217\n",
            "/content/drive/MyDrive/AnomalyDetectionInVideos/files/9ccb7b0b-b186-43ee-9a3b-971c266eae82 175\n",
            "/content/drive/MyDrive/AnomalyDetectionInVideos/files/a2051be4-c866-49e9-9b38-a58562109957 219\n",
            "/content/drive/MyDrive/AnomalyDetectionInVideos/files/afec9df8-bad3-426c-9d44-9a97c2565a64 208\n",
            "/content/drive/MyDrive/AnomalyDetectionInVideos/files/b84bd1f4-7026-495a-9247-4aa3b5dd1b45 217\n",
            "/content/drive/MyDrive/AnomalyDetectionInVideos/files/c4e84b52-593d-40a9-b3e0-549108d58f3e 213\n",
            "/content/drive/MyDrive/AnomalyDetectionInVideos/files/cad1897f-4c81-40ff-96a2-2b722c5f259a 215\n",
            "/content/drive/MyDrive/AnomalyDetectionInVideos/files/d0ffb16d-cc84-4fee-8ed5-677f57615976 205\n",
            "/content/drive/MyDrive/AnomalyDetectionInVideos/files/d6c814d2-5480-41f0-bad4-3daac2f841d9 216\n",
            "/content/drive/MyDrive/AnomalyDetectionInVideos/files/deadb34b-7be2-4478-b292-ac96f9c1494d 196\n",
            "/content/drive/MyDrive/AnomalyDetectionInVideos/files/e7a1a4ba-8f09-4b63-98ab-d299110c0c72 236\n",
            "/content/drive/MyDrive/AnomalyDetectionInVideos/files/eadd83ec-7184-4868-b983-5ea5ef8de3a2 193\n",
            "/content/drive/MyDrive/AnomalyDetectionInVideos/files/f5d70039-7387-4f7b-ac97-38534f444f8e 218\n",
            "/content/drive/MyDrive/AnomalyDetectionInVideos/files/f6832f56-c6e3-4e37-9e77-73df4ff87e94 163\n",
            "Min folder threshold will be 159\n",
            "Processing /content/drive/MyDrive/AnomalyDetectionInVideos/files/001dbbb8-b749-4ce0-a90d-740b8a783f35\n",
            "Processing /content/drive/MyDrive/AnomalyDetectionInVideos/files/083e9a31-84d9-455d-91e7-d1b0921b4921\n",
            "Processing /content/drive/MyDrive/AnomalyDetectionInVideos/files/0b1aab89-cbce-47af-a426-693f45c19acc\n",
            "Processing /content/drive/MyDrive/AnomalyDetectionInVideos/files/1474d8ce-335a-4568-b786-aa01d763e941\n",
            "Processing /content/drive/MyDrive/AnomalyDetectionInVideos/files/1f51d251-79aa-4bb3-b9f3-01a8275dab63\n",
            "Processing /content/drive/MyDrive/AnomalyDetectionInVideos/files/2195f4e0-76c9-465f-9123-8261ae863112\n",
            "Processing /content/drive/MyDrive/AnomalyDetectionInVideos/files/25f477c3-6deb-4ae0-b0ca-1cf107e03dd9\n",
            "Processing /content/drive/MyDrive/AnomalyDetectionInVideos/files/2e900a0f-dc64-4b45-a4cf-5a4a1f92547b\n",
            "Processing /content/drive/MyDrive/AnomalyDetectionInVideos/files/320b7780-a1af-480f-a7cb-b8c5d29c1d4e\n",
            "Processing /content/drive/MyDrive/AnomalyDetectionInVideos/files/4bb580ce-85a2-493d-9956-4d2e86cd4141\n",
            "Processing /content/drive/MyDrive/AnomalyDetectionInVideos/files/6dd659ff-12aa-437a-a5b2-3364a879a5fc\n",
            "Processing /content/drive/MyDrive/AnomalyDetectionInVideos/files/71ec8eb2-5e89-45e0-b019-a3be044c6355\n",
            "Processing /content/drive/MyDrive/AnomalyDetectionInVideos/files/74007bb7-b182-4bf4-9b11-e1bb6606e2ab\n",
            "Processing /content/drive/MyDrive/AnomalyDetectionInVideos/files/769a3c79-f730-4f05-becf-ee9535131173\n",
            "Processing /content/drive/MyDrive/AnomalyDetectionInVideos/files/7927fbca-aca1-4df1-8d3b-788d26c106e1\n",
            "Processing /content/drive/MyDrive/AnomalyDetectionInVideos/files/7be50887-eb8f-473b-b85f-566df6cea1b4\n",
            "Processing /content/drive/MyDrive/AnomalyDetectionInVideos/files/809c6bfb-585f-4158-9dc9-a8ad3e6717a2\n",
            "Processing /content/drive/MyDrive/AnomalyDetectionInVideos/files/897a7710-2a2c-4af6-833d-efd2fc5492fe\n",
            "Processing /content/drive/MyDrive/AnomalyDetectionInVideos/files/9185cf7a-c28d-40dd-8768-5bb28cbeb2c6\n",
            "Processing /content/drive/MyDrive/AnomalyDetectionInVideos/files/935bb3da-3591-42fc-a41a-b514db2b5a3d\n",
            "Processing /content/drive/MyDrive/AnomalyDetectionInVideos/files/938fd6aa-ad18-40e6-90e0-2ee7a397e8cf\n",
            "Processing /content/drive/MyDrive/AnomalyDetectionInVideos/files/9417e18b-f432-4907-b9c7-2a28cd43b1e7\n",
            "Processing /content/drive/MyDrive/AnomalyDetectionInVideos/files/9c67eb54-6db3-4a66-804b-59f5e853f6eb\n",
            "Processing /content/drive/MyDrive/AnomalyDetectionInVideos/files/9ccb7b0b-b186-43ee-9a3b-971c266eae82\n",
            "Processing /content/drive/MyDrive/AnomalyDetectionInVideos/files/a2051be4-c866-49e9-9b38-a58562109957\n",
            "Processing /content/drive/MyDrive/AnomalyDetectionInVideos/files/afec9df8-bad3-426c-9d44-9a97c2565a64\n",
            "Processing /content/drive/MyDrive/AnomalyDetectionInVideos/files/b84bd1f4-7026-495a-9247-4aa3b5dd1b45\n",
            "Processing /content/drive/MyDrive/AnomalyDetectionInVideos/files/c4e84b52-593d-40a9-b3e0-549108d58f3e\n",
            "Processing /content/drive/MyDrive/AnomalyDetectionInVideos/files/cad1897f-4c81-40ff-96a2-2b722c5f259a\n",
            "Processing /content/drive/MyDrive/AnomalyDetectionInVideos/files/d0ffb16d-cc84-4fee-8ed5-677f57615976\n",
            "Processing /content/drive/MyDrive/AnomalyDetectionInVideos/files/d6c814d2-5480-41f0-bad4-3daac2f841d9\n",
            "Processing /content/drive/MyDrive/AnomalyDetectionInVideos/files/deadb34b-7be2-4478-b292-ac96f9c1494d\n",
            "Processing /content/drive/MyDrive/AnomalyDetectionInVideos/files/e7a1a4ba-8f09-4b63-98ab-d299110c0c72\n",
            "Processing /content/drive/MyDrive/AnomalyDetectionInVideos/files/eadd83ec-7184-4868-b983-5ea5ef8de3a2\n",
            "Processing /content/drive/MyDrive/AnomalyDetectionInVideos/files/f5d70039-7387-4f7b-ac97-38534f444f8e\n",
            "Processing /content/drive/MyDrive/AnomalyDetectionInVideos/files/f6832f56-c6e3-4e37-9e77-73df4ff87e94\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "time_distributed (TimeDistri (None, 10, 64, 64, 128)   15616     \n",
            "_________________________________________________________________\n",
            "layer_normalization (LayerNo (None, 10, 64, 64, 128)   256       \n",
            "_________________________________________________________________\n",
            "time_distributed_1 (TimeDist (None, 10, 32, 32, 64)    204864    \n",
            "_________________________________________________________________\n",
            "layer_normalization_1 (Layer (None, 10, 32, 32, 64)    128       \n",
            "_________________________________________________________________\n",
            "conv_lst_m2d (ConvLSTM2D)    (None, 10, 32, 32, 64)    295168    \n",
            "_________________________________________________________________\n",
            "layer_normalization_2 (Layer (None, 10, 32, 32, 64)    128       \n",
            "_________________________________________________________________\n",
            "conv_lst_m2d_1 (ConvLSTM2D)  (None, 10, 32, 32, 32)    110720    \n",
            "_________________________________________________________________\n",
            "layer_normalization_3 (Layer (None, 10, 32, 32, 32)    64        \n",
            "_________________________________________________________________\n",
            "conv_lst_m2d_2 (ConvLSTM2D)  (None, 10, 32, 32, 64)    221440    \n",
            "_________________________________________________________________\n",
            "layer_normalization_4 (Layer (None, 10, 32, 32, 64)    128       \n",
            "_________________________________________________________________\n",
            "time_distributed_2 (TimeDist (None, 10, 64, 64, 64)    102464    \n",
            "_________________________________________________________________\n",
            "layer_normalization_5 (Layer (None, 10, 64, 64, 64)    128       \n",
            "_________________________________________________________________\n",
            "time_distributed_3 (TimeDist (None, 10, 256, 256, 128) 991360    \n",
            "_________________________________________________________________\n",
            "layer_normalization_6 (Layer (None, 10, 256, 256, 128) 256       \n",
            "_________________________________________________________________\n",
            "time_distributed_4 (TimeDist (None, 10, 256, 256, 1)   15489     \n",
            "=================================================================\n",
            "Total params: 1,958,209\n",
            "Trainable params: 1,958,209\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/5\n",
            "270/270 [==============================] - 170s 590ms/step - loss: 0.0359\n",
            "Epoch 2/5\n",
            "270/270 [==============================] - 159s 591ms/step - loss: 0.0097\n",
            "Epoch 3/5\n",
            "270/270 [==============================] - 159s 590ms/step - loss: 0.0049\n",
            "Epoch 4/5\n",
            "270/270 [==============================] - 159s 590ms/step - loss: 0.0031\n",
            "Epoch 5/5\n",
            "270/270 [==============================] - 160s 591ms/step - loss: 0.0032\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LY2HQVWxVllw",
        "outputId": "193006b2-6301-47e9-e2a0-bc25f9815d61",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}